{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebbe0b7",
   "metadata": {},
   "source": [
    "### Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d064aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tempfile, os, zipfile, io\n",
    "\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9db03",
   "metadata": {},
   "source": [
    "Решение для создания списка дат для итерирования взято с [Stackoverflow](https://stackoverflow.com/questions/1060279/iterating-through-a-range-of-dates-in-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cab0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7127c74",
   "metadata": {},
   "source": [
    "### Класс для сбора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f31477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialInfo:\n",
    "    def __init__(self, start_date=None, end_date=None):\n",
    "        ''' \n",
    "        start_date: Первый день, за который надо получить данные. Формат ввода: ДД.ММ.ГГГГ. По умолчанию: 01.01.2010\n",
    "        end_date: Последний день, за который надо получить данные. Формат ввода: ДД.ММ.ГГГГ. По умолчанию: сегодня\n",
    "        '''\n",
    "        # задание дефолтного значения первого дня\n",
    "        if start_date is None:\n",
    "            self.start_date = date(2010, 1, 1)\n",
    "            self.start_date_text = self.start_date.strftime(\"%d.%m.%Y\")\n",
    "        # задание пользовательского значения первого дня\n",
    "        else:\n",
    "            self.start_date_text = start_date\n",
    "            sd = list(map(int, start_date.split('.')))\n",
    "            self.start_date = date(sd[2], sd[1], sd[0])\n",
    "            \n",
    "        # задание дефолтного значения последнего дня\n",
    "        if end_date is None:\n",
    "            self.end_date = date.today()\n",
    "            self.end_date_text = self.end_date.strftime(\"%d.%m.%Y\")\n",
    "        # задание пользовательского значения последнего дня\n",
    "        else:\n",
    "            self.end_date_text = end_date\n",
    "            ed = list(map(int, end_date.split('.')))\n",
    "            self.end_date = date(ed[2], ed[1], ed[0])\n",
    "    \n",
    "    def get_usdrub(self):\n",
    "        '''\n",
    "        Выгружает данные по курсу USDRUB из XML Банка России за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        usd = dict()\n",
    "        \n",
    "        # в XML Банка России даты заданы в формате ДД/ММ/ГГГГ, поэтому переводим атрибуты в нужный формат\n",
    "        st_usd = self.start_date.strftime(\"%d/%m/%Y\")\n",
    "        ed_usd = self.end_date.strftime(\"%d/%m/%Y\")\n",
    "        \n",
    "        url_i = f'http://www.cbr.ru/scripts/XML_dynamic.asp?date_req1={st_usd}&date_req2={ed_usd}&VAL_NM_RQ=R01235'\n",
    "        response_i = requests.get(url_i, headers={'User-Agent': UserAgent().chrome}, timeout=5)\n",
    "        tree_usd = BeautifulSoup(response_i.content, 'html.parser')\n",
    "        \n",
    "        # в XML все записи внесены как record с датой и значением курса \n",
    "        for i in tree_usd.find_all('record'):\n",
    "            usd[i.get('date')] = float(i.value.text.replace(',', '.'))\n",
    "            \n",
    "        return pd.DataFrame.from_dict(usd, orient='index', columns=['usdrub'])\n",
    "        \n",
    "    def get_cb_key_rate(self):\n",
    "        '''\n",
    "        Выгружает данные по ключевой ставке с сайта Банка России за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        key_policy_rate = dict()\n",
    "        url_k = f'https://www.cbr.ru/hd_base/KeyRate/?UniDbQuery.Posted=True&UniDbQuery.From={self.start_date_text}&UniDbQuery.To={self.end_date_text}'\n",
    "        response_k = requests.get(url_k, headers={'User-Agent': UserAgent().chrome}, timeout=5)\n",
    "        tree_key_policy_rate = BeautifulSoup(response_k.content, 'html.parser')\n",
    "        key_rate = pd.read_html(str(tree_key_policy_rate.find('div', {'class': \"table-wrapper\"}).table), index_col='Дата')[0]\n",
    "        key_rate.index.name = None\n",
    "        key_rate['Ставка'] = key_rate['Ставка']/100\n",
    "        key_rate.rename({'Ставка': 'cb_key_rate'}, axis=1, inplace=True)\n",
    "        \n",
    "        return key_rate\n",
    "    \n",
    "    def get_fed_rate(self):\n",
    "        fed_rate = dict()\n",
    "\n",
    "        url_fed = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=PRATES&filetype=zip'\n",
    "        response_fed = requests.get(url_fed, headers={'User-Agent': UserAgent().chrome})\n",
    "\n",
    "        # концепт распаковки взят с stackoverflow, но ссылка потерялась\n",
    "        with response_fed, zipfile.ZipFile(io.BytesIO(response_fed.content)) as archive:\n",
    "            data = archive.read('PRATES_data.xml')\n",
    "\n",
    "        all_fed_data = BeautifulSoup(str(data), 'lxml').find(id='PRATES_POLICY_RATES').find_all('frb:obs')\n",
    "\n",
    "        # НУЖНО ПОПРОБОВАТЬ ПЕРЕПИСАТЬ ФИЛЬТР ПО ДАТЕ\n",
    "        for m in all_fed_data:\n",
    "            date_lst = list(map(int, m.get('time_period').split('-')))\n",
    "            date_dt = date(date_lst[0], date_lst[1], date_lst[2])\n",
    "            if date_dt >= start_date and date_dt <= end_date:\n",
    "                fed_rate[date_dt.strftime(\"%d.%m.%Y\")] = float(m.get('obs_value'))\n",
    "                \n",
    "        return pd.DataFrame.from_dict(fed_rate, orient='index', columns=['fed_rate'])\n",
    "        \n",
    "    def get_gold(self):\n",
    "        '''\n",
    "        Выгружает данные по цене золота из XML Банка России за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        gold_buy = dict()\n",
    "        url_gold = f'http://www.cbr.ru/scripts/xml_metall.asp?date_req1={self.start_date_text}&date_req2={self.end_date_text}'\n",
    "        response_gold = requests.get(url_gold, headers={'User-Agent': UserAgent().chrome})\n",
    "        tree_gold = BeautifulSoup(response_gold.content, 'html.parser')\n",
    "        for j in tree_gold.metall.find_all('record', code='1'):\n",
    "            j_date = j.get('date')\n",
    "            gold_buy[j_date] = float(j.buy.text.replace(',', '.'))\n",
    "            \n",
    "        return pd.DataFrame.from_dict(gold_buy, orient='index', columns=['gold'])\n",
    "    \n",
    "    def get_imoex(self):\n",
    "        '''\n",
    "        Выгружает данные по ценам открытия и закрытия Индекса Мосбиржи из ISS Московской Биржи за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        imoex = dict()\n",
    "\n",
    "        st_imoex = self.start_date.strftime(\"%Y-%m-%d\")\n",
    "        ed_imoex = self.end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # этот кусок нужен, потому что система по запросу выдает только 100 дат. В инструкции к ISS\n",
    "        # Московской биржи есть более элегантное решение этой проблемы, но по неведомым нам причинам\n",
    "        # оно не работает. Поэтому боремся, как можем\n",
    "        \n",
    "        url_im = f'https://iss.moex.com/iss/history/engines/stock/markets/index/sessions/SNDX/securities/IMOEX.xml?from={st_imoex}&till={ed_imoex}'\n",
    "        response_im = requests.get(url_im, headers={'User-Agent': UserAgent().chrome}, timeout=5)\n",
    "        tree_im = BeautifulSoup(response_im.content, 'lxml')\n",
    "\n",
    "        total_values = int(tree_im.find('data', id='history.cursor').rows.row.get('total'))\n",
    "\n",
    "        imoex_urls = []\n",
    "\n",
    "        total_days = np.arange(100, (self.end_date - self.start_date).days+100, 100)\n",
    "\n",
    "        for start, end in zip(np.arange(0, (self.end_date - self.start_date).days, 100), total_days):\n",
    "            url_start = (self.start_date+timedelta(days=int(start))).strftime(\"%Y-%m-%d\")\n",
    "            url_end = (self.start_date+timedelta(days=int(end))).strftime(\"%Y-%m-%d\")\n",
    "            imoex_urls.append(f'https://iss.moex.com/iss/history/engines/stock/markets/index/sessions/SNDX/securities/IMOEX.xml?from={url_start}&till={url_end}')\n",
    "\n",
    "\n",
    "        for url_im in imoex_urls:\n",
    "            response_im = requests.get(url_im, headers={'User-Agent': UserAgent().chrome}, timeout=5)\n",
    "            tree_im = BeautifulSoup(response_im.content, 'lxml')\n",
    "\n",
    "            # до -1 элемента, потому что также есть row со значениями \n",
    "            # index, total и start, т.е. служебная строка\n",
    "            for moex_value in tree_im.find_all('row')[:-1]: \n",
    "                # переводим дату из исходного формата tradedate=\"YYYY-MM-DD\" в формат \"DD.MM.YYYY\"\n",
    "                moex_date = '.'.join(moex_value.get('tradedate').split('-')[::-1]) \n",
    "                # записываем цены открытия и закрытия индекса на дату в словарь словарей\n",
    "                imoex[moex_date] = dict()\n",
    "                imoex[moex_date]['imoex_open'] = float(moex_value.get('open'))\n",
    "                imoex[moex_date]['imoex_close'] = float(moex_value.get('close'))\n",
    "                \n",
    "        return pd.DataFrame.from_dict(imoex, orient='index', columns=['imoex_open', 'imoex_close'])\n",
    "        \n",
    "    def get_all(self):\n",
    "        '''\n",
    "        Выгружает данные по цене золота, курсу USDRUB, ключевой ставке Банка России, ценам открытия и закрытия Индекса Мосбиржи за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        gold_and_usd = pd.merge(self.get_usdrub(),self.get_gold(),  \n",
    "                                how='left', left_index=True, right_index=True)\n",
    "        gu_cb = pd.merge(gold_and_usd, self.get_cb_key_rate(), \n",
    "                        how='left', left_index=True, right_index=True)\n",
    "        gu_cb_fed = pd.merge(gu_cb, self.get_fed_rate(), \n",
    "                             how='left', left_index=True, right_index=True)\n",
    "        \n",
    "        return pd.merge(gu_cb_fed, self.get_imoex(), \n",
    "                        how='left', left_index=True, right_index=True)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
