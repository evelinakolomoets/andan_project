{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebbe0b7",
   "metadata": {},
   "source": [
    "### Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d064aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tempfile, os, zipfile, io\n",
    "\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9db03",
   "metadata": {},
   "source": [
    "Решение для создания списка дат для итерирования взято с [Stackoverflow](https://stackoverflow.com/questions/1060279/iterating-through-a-range-of-dates-in-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cab0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69bd839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_ru_cpi(r, dframe): \n",
    "    month = int(r['date_split'][1])\n",
    "    year = int(r['date_split'][2])\n",
    "    return dframe.loc[month, year]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7127c74",
   "metadata": {},
   "source": [
    "### Класс для сбора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f31477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialInfo:\n",
    "    def __init__(self, start_date=None, end_date=None):\n",
    "        ''' \n",
    "        start_date: Первый день, за который надо получить данные. Формат ввода: ДД.ММ.ГГГГ. По умолчанию: 01.01.2010\n",
    "        end_date: Последний день, за который надо получить данные. Формат ввода: ДД.ММ.ГГГГ. По умолчанию: вчера\n",
    "        '''\n",
    "        # задание дефолтного значения первого дня\n",
    "        if start_date is None:\n",
    "            self.start_date = date(2010, 1, 1)\n",
    "            self.start_date_text = self.start_date.strftime(\"%d.%m.%Y\")\n",
    "        # задание пользовательского значения первого дня\n",
    "        else:\n",
    "            self.start_date_text = start_date\n",
    "            sd = list(map(int, start_date.split('.')))\n",
    "            self.start_date = date(sd[2], sd[1], sd[0])\n",
    "            \n",
    "        # задание дефолтного значения последнего дня\n",
    "        if end_date is None:\n",
    "            self.end_date = date.today()\n",
    "            self.end_date_text = self.end_date.strftime(\"%d.%m.%Y\")\n",
    "        # задание пользовательского значения последнего дня\n",
    "        else:\n",
    "            self.end_date_text = end_date\n",
    "            ed = list(map(int, end_date.split('.')))\n",
    "            self.end_date = date(ed[2], ed[1], ed[0])\n",
    "    \n",
    "    def get_usdrub(self):\n",
    "        '''\n",
    "        Выгружает данные по курсу USDRUB из XML Банка России за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        usd = dict()\n",
    "        \n",
    "        # в XML Банка России даты заданы в формате ДД/ММ/ГГГГ, поэтому переводим атрибуты в нужный формат\n",
    "        st_usd = self.start_date.strftime(\"%d/%m/%Y\")\n",
    "        ed_usd = self.end_date.strftime(\"%d/%m/%Y\")\n",
    "        \n",
    "        url_i = f'http://www.cbr.ru/scripts/XML_dynamic.asp?date_req1={st_usd}&date_req2={ed_usd}&VAL_NM_RQ=R01235'\n",
    "        response_i = requests.get(url_i, headers={'User-Agent': UserAgent().chrome}, timeout=5)\n",
    "        tree_usd = BeautifulSoup(response_i.content, 'html.parser')\n",
    "        \n",
    "        # в XML все записи внесены как record с датой и значением курса \n",
    "        for i in tree_usd.find_all('record'):\n",
    "            usd[i.get('date')] = float(i.value.text.replace(',', '.'))\n",
    "        \n",
    "        usdrub = pd.DataFrame.from_dict(usd, orient='index', columns=['usdrub'])\n",
    "        \n",
    "        usdrub.index = pd.to_datetime(usdrub.index, format='%d.%m.%Y')\n",
    "        \n",
    "        usdrub = usdrub.resample('1D').mean()\n",
    "        usdrub = usdrub.sort_index()\n",
    "        \n",
    "        usdrub.index = usdrub.index.strftime('%d.%m.%Y')\n",
    "            \n",
    "        return usdrub\n",
    "        \n",
    "    def get_cb_key_rate(self):\n",
    "        '''\n",
    "        Выгружает данные по ключевой ставке с сайта Банка России за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "\n",
    "        key_policy_rate = dict()\n",
    "        \n",
    "        # на сайте ЦБ данные доступны с 17.09.2013. Чтобы избежать риск того, что в ближайшее время \n",
    "        # эту дату поменяют, выгружаем данные до 2014 года с другого сайта\n",
    "        \n",
    "        threshold = date(2014, 1, 1)\n",
    "        if self.start_date < date(2014, 1, 1):\n",
    "            url_additional = 'https://www.audit-it.ru/inform/peni/stavka_cb.php'\n",
    "            additional = pd.read_html(url_additional)[0]\n",
    "            additional = additional.drop('Документ, в котором сообщена ставка', axis=1)\n",
    "            additional['Срок, с которого установлена ставка'] = pd.to_datetime(\n",
    "                                                    additional['Срок, с которого установлена ставка'], format='%d.%m.%Y')\n",
    "\n",
    "            additional = additional.set_index('Срок, с которого установлена ставка')\n",
    "            \n",
    "            additional.index.names = [None]\n",
    "\n",
    "            # на этом сайте публикуются только даты изменения ключевой ставки, поэтому заполним пропущенные даты\n",
    "            additional = additional.resample('1D').mean().ffill()\n",
    "\n",
    "            additional.index = additional.index.strftime('%d.%m.%Y')\n",
    "            \n",
    "            additional.rename({\"Размер ставки рефинансирования (%, годовых)\": \"cb_key_rate\"}, \n",
    "                              axis=1, inplace=True)\n",
    "            \n",
    "        url_k = f'https://www.cbr.ru/hd_base/KeyRate/?UniDbQuery.Posted=True&UniDbQuery.From={threshold.strftime(\"%d.%m.%Y\")}&UniDbQuery.To={self.end_date_text}'\n",
    "        response_k = requests.get(url_k, headers={'User-Agent': UserAgent().chrome}, timeout=5)\n",
    "        tree_key_policy_rate = BeautifulSoup(response_k.content, 'html.parser')\n",
    "        \n",
    "        key_rate = pd.read_html(str(tree_key_policy_rate.find('div', {'class': \"table-wrapper\"}).table), index_col='Дата')[0]\n",
    "        key_rate.index.name = None\n",
    "        \n",
    "        # преобразования для сортировки по возрастанию по дате\n",
    "        key_rate.index = pd.to_datetime(key_rate.index, format='%d.%m.%Y')\n",
    "        key_rate = key_rate.sort_index()\n",
    "        key_rate.index = key_rate.index.strftime('%d.%m.%Y')\n",
    "        \n",
    "        key_rate['Ставка'] = key_rate['Ставка']/100\n",
    "        key_rate.rename({'Ставка': 'cb_key_rate'}, axis=1, inplace=True)\n",
    "        \n",
    "        return pd.concat([additional[self.start_date_text:threshold.strftime(\"%d.%m.%Y\")], key_rate])\n",
    "    \n",
    "    def get_fed_rate(self):\n",
    "        '''\n",
    "        Выгружает данные о учетной ставке с сайта ФРС за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        \n",
    "        fed_rate = dict()\n",
    "\n",
    "        url_fed = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=PRATES&filetype=zip'\n",
    "        response_fed = requests.get(url_fed, headers={'User-Agent': UserAgent().chrome})\n",
    "\n",
    "        # концепт распаковки взят с stackoverflow, но ссылка потерялась\n",
    "        with response_fed, zipfile.ZipFile(io.BytesIO(response_fed.content)) as archive:\n",
    "            data = archive.read('PRATES_data.xml')\n",
    "\n",
    "        all_fed_data = BeautifulSoup(str(data), 'lxml').find(id='PRATES_POLICY_RATES').find_all('frb:obs')\n",
    "\n",
    "        for m in all_fed_data:\n",
    "            date_lst = list(map(int, m.get('time_period').split('-')))\n",
    "            date_dt = date(date_lst[0], date_lst[1], date_lst[2])\n",
    "            if date_dt >= self.start_date and date_dt <= self.end_date:\n",
    "                fed_rate[date_dt.strftime(\"%d.%m.%Y\")] = float(m.get('obs_value'))\n",
    "                \n",
    "        return pd.DataFrame.from_dict(fed_rate, orient='index', columns=['fed_rate'])\n",
    "        \n",
    "    def get_gold(self):\n",
    "        '''\n",
    "        Выгружает данные по цене золота из XML Банка России за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        \n",
    "        gold_buy = dict()\n",
    "        url_gold = f'http://www.cbr.ru/scripts/xml_metall.asp?date_req1={self.start_date_text}&date_req2={self.end_date_text}'\n",
    "        response_gold = requests.get(url_gold, headers={'User-Agent': UserAgent().chrome})\n",
    "        tree_gold = BeautifulSoup(response_gold.content, 'html.parser')\n",
    "        for j in tree_gold.metall.find_all('record', code='1'):\n",
    "            j_date = j.get('date')\n",
    "            gold_buy[j_date] = float(j.buy.text.replace(',', '.'))\n",
    "            \n",
    "        return pd.DataFrame.from_dict(gold_buy, orient='index', columns=['gold'])\n",
    "    \n",
    "    def get_imoex(self):\n",
    "        '''\n",
    "        Выгружает данные по ценам открытия и закрытия Индекса Мосбиржи из ISS Московской Биржи за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        imoex = dict()\n",
    "\n",
    "        st_imoex = self.start_date.strftime(\"%Y-%m-%d\")\n",
    "        ed_imoex = self.end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # этот кусок нужен, потому что система по запросу выдает только 100 дат. В инструкции к ISS\n",
    "        # Московской биржи есть более элегантное решение этой проблемы, но по неведомым нам причинам\n",
    "        # оно не работает. Поэтому боремся, как можем\n",
    "        \n",
    "        url_im = f'https://iss.moex.com/iss/history/engines/stock/markets/index/sessions/SNDX/securities/IMOEX.xml?from={st_imoex}&till={ed_imoex}'\n",
    "        response_im = requests.get(url_im, headers={'User-Agent': UserAgent().chrome}, timeout=5)\n",
    "        tree_im = BeautifulSoup(response_im.content, 'lxml')\n",
    "\n",
    "        imoex_urls = []\n",
    "\n",
    "        total_days = np.arange(100, (self.end_date - self.start_date).days+100, 100)\n",
    "\n",
    "        for start, end in zip(np.arange(0, (self.end_date - self.start_date).days, 100), total_days):\n",
    "            url_start = (self.start_date+timedelta(days=int(start))).strftime(\"%Y-%m-%d\")\n",
    "            url_end = (self.start_date+timedelta(days=int(end))).strftime(\"%Y-%m-%d\")\n",
    "            imoex_urls.append(f'https://iss.moex.com/iss/history/engines/stock/markets/index/sessions/SNDX/securities/IMOEX.xml?from={url_start}&till={url_end}')\n",
    "\n",
    "\n",
    "        for url_im in imoex_urls:\n",
    "            response_im = requests.get(url_im, headers={'User-Agent': UserAgent().chrome}, timeout=5)\n",
    "            tree_im = BeautifulSoup(response_im.content, 'lxml')\n",
    "\n",
    "            # до -1 элемента, потому что также есть row со значениями \n",
    "            # index, total и start, т.е. служебная строка\n",
    "            for moex_value in tree_im.find_all('row')[:-1]: \n",
    "                # переводим дату из исходного формата tradedate=\"YYYY-MM-DD\" в формат \"DD.MM.YYYY\"\n",
    "                moex_date = '.'.join(moex_value.get('tradedate').split('-')[::-1]) \n",
    "                # записываем цены открытия и закрытия индекса на дату в словарь словарей\n",
    "                imoex[moex_date] = dict()\n",
    "                imoex[moex_date]['imoex_open'] = float(moex_value.get('open'))\n",
    "                imoex[moex_date]['imoex_close'] = float(moex_value.get('close'))\n",
    "                \n",
    "        return pd.DataFrame.from_dict(imoex, orient='index', columns=['imoex_open', 'imoex_close'])\n",
    "    \n",
    "    def get_ru_cpi(self):\n",
    "        '''\n",
    "        Выгружает данные по значению Индекса Потребительских цен (ИПЦ) в России с сайта Росстата за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        url_ru_cpi = 'https://rosstat.gov.ru/storage/mediabank/Ipc_mes-3.xlsx'\n",
    "\n",
    "        file_ru_cpi = urllib.request.urlopen(url_ru_cpi).read()\n",
    "\n",
    "        all_ru_cpi = pd.read_excel(file_ru_cpi, sheet_name='01', skiprows=3, header=0, nrows=13)\n",
    "\n",
    "        # строка \"к концу предыдущего месяца\" не нужна\n",
    "        all_ru_cpi.drop(0, inplace=True) \n",
    "\n",
    "        # строка с названиями месяцев в исходном файле не подписана, подпишем её\n",
    "        all_ru_cpi.rename({'Unnamed: 0': 'месяц'}, axis='columns', inplace=True) \n",
    "        years_needed = all_ru_cpi.loc[:, self.start_date.year:self.end_date.year]\n",
    "\n",
    "        ru_cpi = pd.DataFrame()\n",
    "        ru_cpi['date'] = [i.strftime(\"%d.%m.%Y\") for i in daterange(self.start_date, self.end_date)]\n",
    "        ru_cpi['date_split'] = ru_cpi['date'].str.split('.')\n",
    "        ru_cpi['ru_cpi'] = ru_cpi.apply(lambda row: categorise_ru_cpi(row, years_needed), axis=1)\n",
    "        ru_cpi.drop('date_split', axis=1, inplace=True)\n",
    "        ru_cpi = ru_cpi.set_index('date')\n",
    "        ru_cpi.index.names = [None]\n",
    "        return ru_cpi\n",
    "    \n",
    "    def get_us_cpi(self):\n",
    "        '''\n",
    "        Выгружает данные по значению Индекса Потребительских цен (ИПЦ) в США с сайта ФРБ St.Louis за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        # к сожалению, организация, официально публикующая инфляцию в США, U.S. Bureau of Labor Statistics, \n",
    "        # судя по всему, банит российские ip-адреса\n",
    "\n",
    "        # в найденном источнике 1982-1984 принято за 100, что бы это ни значило\n",
    "        all_us_cpi = pd.read_csv('https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1138&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=CPIAUCSL&scale=left&cosd=1947-01-01&coed=2023-03-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2023-05-01&revision_date=2023-05-01&nd=1947-01-01')\n",
    "\n",
    "        # чтобы вывести ИПЦ месяц-к-месяцу, зная ИПЦ к базовому периду, нужно ИПЦ t+1 периода поделить \n",
    "        # на ИПЦ t периода и умножить на 100, это следует из формулы: сумма по корзине (P_t*Q_0)/(P_0*Q_0) * 100\n",
    "\n",
    "        # чтобы поделить было проще, создадим дополнительную колонку, где все значения будут сдвинуты\n",
    "        # на одну позицию вниз\n",
    "        all_us_cpi['CPIAUCSL_shift'] = np.roll(all_us_cpi['CPIAUCSL'], 1)\n",
    "        all_us_cpi['us_cpi'] = all_us_cpi['CPIAUCSL_shift']/all_us_cpi['CPIAUCSL'] * 100\n",
    "\n",
    "        # обработка данных о дате\n",
    "        all_us_cpi['DATE'] = pd.to_datetime(all_us_cpi['DATE'], format='%Y-%m-%d')\n",
    "\n",
    "        all_us_cpi = all_us_cpi.set_index('DATE')\n",
    "        all_us_cpi.index.names = [None]\n",
    "        \n",
    "        # заполняем пропущенные дни, т.к. данные на 1 число каждого месяца\n",
    "        # пропуски на весь месяц заполним ИПЦ на 1 число этого же месяца\n",
    "        all_us_cpi = all_us_cpi.resample('1D').mean().ffill()\n",
    "        all_us_cpi.index = all_us_cpi.index.strftime('%d.%m.%Y')\n",
    "        all_us_cpi.drop(['CPIAUCSL', 'CPIAUCSL_shift'], axis=1, inplace=True)\n",
    "\n",
    "        return all_us_cpi[self.start_date_text:]\n",
    "    \n",
    "    def get_holidays(self):\n",
    "        '''Выгружает выходные и праздничные дни в соответствии с производственным календарем за даты, указанные в атрибутах объекта'''\n",
    "        all_holidays = dict()\n",
    "\n",
    "        years = np.arange(self.start_date.year, self.end_date.year+1)\n",
    "\n",
    "        months = np.arange(12)\n",
    "\n",
    "        for y in years:\n",
    "            calendar_url = f'https://calendar.yoip.ru/work/{y}-proizvodstvennyj-calendar.html'\n",
    "            cal = requests.get(calendar_url, headers={'User-Agent': UserAgent().chrome}, timeout=5)\n",
    "            tree_cal = BeautifulSoup(cal.content, 'html.parser')\n",
    "            for m in months:\n",
    "                netraboty_m = [int(i.text) for i \n",
    "                             in tree_cal.find_all('table')[m].find_all('td', {'class': '_hd danger tt-hd'})]\n",
    "                netraboty_m.extend([int(i.text) for i \n",
    "                                  in tree_cal.find_all('table')[m].find_all('td', {'class': '_hd warning tt-hd'})])\n",
    "                netraboty_m.extend([int(i.text) for i \n",
    "                                 in tree_cal.find_all('table')[m].find_all('td', {'class': '_hd warning'})])\n",
    "                netraboty_m = [date(y, m+1, i) for i in sorted(netraboty_m)]\n",
    "                for day in netraboty_m:\n",
    "                    all_holidays[day.strftime(\"%d.%m.%Y\")] = 'day off'\n",
    "        \n",
    "        calendar_df = pd.DataFrame.from_dict(all_holidays, orient='index', columns=['workday'])\n",
    "        return calendar_df\n",
    "\n",
    "    def get_all(self):\n",
    "        '''\n",
    "        Выгружает данные по цене золота, курсу USDRUB, ключевой ставке Банка России, ценам открытия и закрытия Индекса Мосбиржи, ИПЦ в РФ за даты, указанные в атрибутах объекта.\n",
    "        '''\n",
    "        df = pd.merge(self.get_usdrub(),self.get_gold(),  \n",
    "                                how='left', left_index=True, right_index=True)\n",
    "        df = pd.merge(df, self.get_cb_key_rate(), \n",
    "                        how='left', left_index=True, right_index=True)\n",
    "        df = pd.merge(df, self.get_fed_rate(), \n",
    "                             how='left', left_index=True, right_index=True)\n",
    "        df = pd.merge(df, self.get_imoex(), \n",
    "                        how='left', left_index=True, right_index=True)\n",
    "        df = pd.merge(df, self.get_ru_cpi(), how='left', left_index=True, right_index=True)\n",
    "        \n",
    "        df = pd.merge(df, self.get_us_cpi(), how='left', left_index=True, right_index=True)\n",
    "        \n",
    "        df.index = pd.to_datetime(df.index, format='%d.%m.%Y')\n",
    "        df = df.sort_index()\n",
    "        df.index = df.index.strftime('%d.%m.%Y')\n",
    "        df = pd.merge(df, self.get_holidays(), how='left', left_index=True, right_index=True)\n",
    "        \n",
    "        df['workday'] = df['workday'].fillna('workday')\n",
    "        \n",
    "        return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
